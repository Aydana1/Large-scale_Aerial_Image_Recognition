{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Random crop and rotation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0 True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.modeling.box_regression import Box2BoxTransform\n",
    "from detectron2.modeling.matcher import Matcher\n",
    "from detectron2.solver.build import get_default_optimizer_params\n",
    "from detectron2.data.build import build_batch_data_loader, get_detection_dataset_dicts\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data.common import DatasetFromList, MapDataset\n",
    "from detectron2.data.dataset_mapper import DatasetMapper\n",
    "from detectron2.data.samplers import TrainingSampler\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.layers import ShapeSpec\n",
    "# Backbone\n",
    "from resnet import ResNet, BasicStem, BasicBlock, BottleneckBlock, DeformBottleneckBlock\n",
    "# Proposal Generator\n",
    "from rpn import RPN, StandardRPNHead\n",
    "from anchor_generator import DefaultAnchorGenerator\n",
    "# Backbone\n",
    "from fpn import FPN, LastLevelMaxPool\n",
    "# ROI Heads\n",
    "from fast_rcnn import FastRCNNOutputLayers\n",
    "from box_head import FastRCNNConvFCHead\n",
    "from roi_heads import StandardROIHeads\n",
    "from poolers import ROIPooler\n",
    "\n",
    "from rcnn import GeneralizedRCNN as RCNN\n",
    "from trainer import DefaultTrainer, DefaultPredictor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "seed = 217\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: True\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ()\n",
      "  TRAIN: ('iSAID_train',)\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "  RANDOM_FLIP: horizontal\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NORM: \n",
      "    NUM_CLASSES: 80\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 128\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 15\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    CONV_DIMS: [-1]\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "OUTPUT_DIR: outputs\n",
      "SEED: -1\n",
      "SOLVER:\n",
      "  AMP:\n",
      "    ENABLED: False\n",
      "  BASE_LR: 0.0025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5000\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 100000\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: ()\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: None\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 0\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"config.yaml\")\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Define the FPN bottom-up part (which is a ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = ShapeSpec(channels=len(cfg.MODEL.PIXEL_MEAN))\n",
    "norm = cfg.MODEL.RESNETS.NORM\n",
    "stem = BasicStem(\n",
    "    in_channels     = input_shape.channels,\n",
    "    out_channels    = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS,\n",
    "    norm            = norm,\n",
    ")\n",
    "\n",
    "freeze_at           = cfg.MODEL.BACKBONE.FREEZE_AT\n",
    "out_features        = cfg.MODEL.RESNETS.OUT_FEATURES\n",
    "depth               = cfg.MODEL.RESNETS.DEPTH\n",
    "num_groups          = cfg.MODEL.RESNETS.NUM_GROUPS\n",
    "width_per_group     = cfg.MODEL.RESNETS.WIDTH_PER_GROUP\n",
    "bottleneck_channels = num_groups * width_per_group\n",
    "in_channels         = cfg.MODEL.RESNETS.STEM_OUT_CHANNELS\n",
    "out_channels        = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS\n",
    "stride_in_1x1       = cfg.MODEL.RESNETS.STRIDE_IN_1X1\n",
    "res5_dilation       = cfg.MODEL.RESNETS.RES5_DILATION\n",
    "deform_on_per_stage = cfg.MODEL.RESNETS.DEFORM_ON_PER_STAGE\n",
    "deform_modulated    = cfg.MODEL.RESNETS.DEFORM_MODULATED\n",
    "deform_num_groups   = cfg.MODEL.RESNETS.DEFORM_NUM_GROUPS\n",
    "\n",
    "# assert res5_dilation in {1, 2}, \"res5_dilation cannot be {}.\".format(res5_dilation)\n",
    "\n",
    "num_blocks_per_stage = {\n",
    "    18: [2, 2, 2, 2],\n",
    "    34: [3, 4, 6, 3],\n",
    "    50: [3, 4, 6, 3],\n",
    "    101: [3, 4, 23, 3],\n",
    "    152: [3, 8, 36, 3],\n",
    "}[depth]\n",
    "\n",
    "if depth in [18, 34]:\n",
    "    assert out_channels == 64, \"Must set MODEL.RESNETS.RES2_OUT_CHANNELS = 64 for R18/R34\"\n",
    "    assert not any(\n",
    "        deform_on_per_stage\n",
    "    ), \"MODEL.RESNETS.DEFORM_ON_PER_STAGE unsupported for R18/R34\"\n",
    "    assert res5_dilation == 1, \"Must set MODEL.RESNETS.RES5_DILATION = 1 for R18/R34\"\n",
    "    assert num_groups == 1, \"Must set MODEL.RESNETS.NUM_GROUPS = 1 for R18/R34\"\n",
    "\n",
    "stages = []\n",
    "\n",
    "for idx, stage_idx in enumerate(range(2, 6)):\n",
    "    # res5_dilation is used this way as a convention in R-FCN & Deformable Conv paper\n",
    "    dilation = res5_dilation if stage_idx == 5 else 1\n",
    "    first_stride = 1 if idx == 0 or (stage_idx == 5 and dilation == 2) else 2\n",
    "    stage_kargs = {\n",
    "        \"num_blocks\": num_blocks_per_stage[idx],\n",
    "        \"stride_per_block\": [first_stride] + [1] * (num_blocks_per_stage[idx] - 1),\n",
    "        \"in_channels\": in_channels,\n",
    "        \"out_channels\": out_channels,\n",
    "        \"norm\": norm,\n",
    "    }\n",
    "    # Use BasicBlock for R18 and R34.\n",
    "    if depth in [18, 34]:\n",
    "        stage_kargs[\"block_class\"] = BasicBlock\n",
    "    else:\n",
    "        stage_kargs[\"bottleneck_channels\"] = bottleneck_channels\n",
    "        stage_kargs[\"stride_in_1x1\"] = stride_in_1x1\n",
    "        stage_kargs[\"dilation\"] = dilation\n",
    "        stage_kargs[\"num_groups\"] = num_groups\n",
    "        if deform_on_per_stage[idx]:\n",
    "            stage_kargs[\"block_class\"] = DeformBottleneckBlock\n",
    "            stage_kargs[\"deform_modulated\"] = deform_modulated\n",
    "            stage_kargs[\"deform_num_groups\"] = deform_num_groups\n",
    "        else:\n",
    "            stage_kargs[\"block_class\"] = BottleneckBlock\n",
    "    blocks = ResNet.make_stage(**stage_kargs)\n",
    "    in_channels = out_channels\n",
    "    out_channels *= 2\n",
    "    bottleneck_channels *= 2\n",
    "    stages.append(blocks)\n",
    "\n",
    "# fpn_bottom_up (type Backbone > nn.Module)\n",
    "fpn_bottom_up = ResNet(stem, stages, out_features=out_features, freeze_at=freeze_at)\n",
    "# fpn_bottom_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = FPN(\n",
    "    bottom_up       = fpn_bottom_up,\n",
    "    in_features     = cfg.MODEL.FPN.IN_FEATURES,\n",
    "    out_channels    = cfg.MODEL.FPN.OUT_CHANNELS,\n",
    "    norm            = cfg.MODEL.FPN.NORM,\n",
    "    fuse_type       = cfg.MODEL.FPN.FUSE_TYPE,\n",
    "    top_block       = LastLevelMaxPool(),\n",
    ")\n",
    "# backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Region Proposal Network (RPN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Anchor generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = backbone.output_shape()\n",
    "input_shape = [input_shape[f] for f in cfg.MODEL.RPN.IN_FEATURES]\n",
    "\n",
    "anchor_generator = DefaultAnchorGenerator(\n",
    "    sizes           = cfg.MODEL.ANCHOR_GENERATOR.SIZES, \n",
    "    aspect_ratios   = cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS,\n",
    "    strides         = [x.stride for x in input_shape],\n",
    "    offset          = cfg.MODEL.ANCHOR_GENERATOR.OFFSET,\n",
    ")\n",
    "# anchor_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RPN head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = backbone.output_shape()\n",
    "input_shape = [input_shape[f] for f in cfg.MODEL.RPN.IN_FEATURES]\n",
    "in_channels = [s.channels for s in input_shape]\n",
    "assert len(set(in_channels)) == 1, \"Each level must have the same channel!\"\n",
    "in_channels = in_channels[0]\n",
    "\n",
    "assert (\n",
    "    len(set(anchor_generator.num_anchors)) == 1\n",
    "), \"Each level must have the same number of anchors per spatial position\"\n",
    "\n",
    "rpn_head = StandardRPNHead(\n",
    "    in_channels = in_channels,\n",
    "    num_anchors = anchor_generator.num_anchors[0],\n",
    "    box_dim     = anchor_generator.box_dim,\n",
    "    conv_dims   = cfg.MODEL.RPN.CONV_DIMS,\n",
    ")\n",
    "# rpn_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Region Proposal Generator (RPN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_generator = RPN(\n",
    "    in_features             = cfg.MODEL.RPN.IN_FEATURES,\n",
    "    head                    = rpn_head,\n",
    "    anchor_generator        = anchor_generator,\n",
    "    anchor_matcher          = Matcher(\n",
    "                                cfg.MODEL.RPN.IOU_THRESHOLDS, cfg.MODEL.RPN.IOU_LABELS, allow_low_quality_matches=True\n",
    "                                ),\n",
    "    box2box_transform       = Box2BoxTransform(weights=cfg.MODEL.RPN.BBOX_REG_WEIGHTS),\n",
    "    batch_size_per_image    = cfg.MODEL.RPN.BATCH_SIZE_PER_IMAGE,\n",
    "    positive_fraction       = cfg.MODEL.RPN.POSITIVE_FRACTION,\n",
    "    pre_nms_topk            = (cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN, cfg.MODEL.RPN.POST_NMS_TOPK_TEST),\n",
    "    post_nms_topk           = (cfg.MODEL.RPN.POST_NMS_TOPK_TRAIN, cfg.MODEL.RPN.POST_NMS_TOPK_TEST),\n",
    "    nms_thresh              = cfg.MODEL.RPN.NMS_THRESH,\n",
    "    min_box_size            = cfg.MODEL.PROPOSAL_GENERATOR.MIN_SIZE,\n",
    "    anchor_boundary_thresh  = cfg.MODEL.RPN.BOUNDARY_THRESH,\n",
    "    loss_weight             = {\n",
    "                                \"loss_rpn_cls\": cfg.MODEL.RPN.LOSS_WEIGHT,\n",
    "                                \"loss_rpn_loc\": cfg.MODEL.RPN.BBOX_REG_LOSS_WEIGHT * cfg.MODEL.RPN.LOSS_WEIGHT,\n",
    "                                },\n",
    "    box_reg_loss_type       = cfg.MODEL.RPN.BBOX_REG_LOSS_TYPE,\n",
    "    smooth_l1_beta          = cfg.MODEL.RPN.SMOOTH_L1_BETA,\n",
    ")\n",
    "# proposal_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Region of Interest Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = backbone.output_shape()\n",
    "input_shape = [input_shape[f] for f in cfg.MODEL.RPN.IN_FEATURES]\n",
    "in_channels = [s.channels for s in input_shape]\n",
    "assert len(set(in_channels)) == 1, \"Each level must have the same channel!\"\n",
    "in_channels = in_channels[0]\n",
    "\n",
    "box_head = FastRCNNConvFCHead(\n",
    "    input_shape = ShapeSpec(\n",
    "                    channels    = in_channels, \n",
    "                    height      = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION, \n",
    "                    width       = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\n",
    "                    ),\n",
    "    conv_dims   = [cfg.MODEL.ROI_BOX_HEAD.CONV_DIM] * cfg.MODEL.ROI_BOX_HEAD.NUM_CONV,\n",
    "    fc_dims     = [cfg.MODEL.ROI_BOX_HEAD.FC_DIM] * cfg.MODEL.ROI_BOX_HEAD.NUM_FC,\n",
    "    conv_norm   = cfg.MODEL.ROI_BOX_HEAD.NORM,\n",
    ")\n",
    "\n",
    "box_predictor = FastRCNNOutputLayers(\n",
    "        input_shape             = box_head.output_shape,\n",
    "        box2box_transform       = Box2BoxTransform(weights=cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS),\n",
    "        num_classes             = cfg.MODEL.ROI_HEADS.NUM_CLASSES,\n",
    "        test_score_thresh       = cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST,\n",
    "        test_nms_thresh         = cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST,\n",
    "        test_topk_per_image     = cfg.TEST.DETECTIONS_PER_IMAGE,\n",
    "        cls_agnostic_bbox_reg   = cfg.MODEL.ROI_BOX_HEAD.CLS_AGNOSTIC_BBOX_REG,\n",
    "        smooth_l1_beta          = cfg.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA,\n",
    "        box_reg_loss_type       = cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_TYPE,\n",
    "        loss_weight             = {\"loss_box_reg\": cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_LOSS_WEIGHT},\n",
    ")\n",
    "# box_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = backbone.output_shape()\n",
    "\n",
    "roi_pooler = ROIPooler(\n",
    "    output_size     = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION,\n",
    "    scales          = tuple(1.0 / input_shape[k].stride for k in cfg.MODEL.ROI_HEADS.IN_FEATURES),\n",
    "    sampling_ratio  = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO,\n",
    "    pooler_type     = cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE,\n",
    ")\n",
    "\n",
    "roi_heads = StandardROIHeads(\n",
    "    box_in_features         = cfg.MODEL.ROI_HEADS.IN_FEATURES,\n",
    "    box_pooler              = roi_pooler,\n",
    "    box_head                = box_head,\n",
    "    box_predictor           = box_predictor,\n",
    "    num_classes             = cfg.MODEL.ROI_HEADS.NUM_CLASSES,\n",
    "    batch_size_per_image    = cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE,\n",
    "    positive_fraction       = cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION,\n",
    "    proposal_matcher        = Matcher(\n",
    "                                cfg.MODEL.ROI_HEADS.IOU_THRESHOLDS,\n",
    "                                cfg.MODEL.ROI_HEADS.IOU_LABELS,\n",
    "                                allow_low_quality_matches=False,\n",
    "                                ),\n",
    "    proposal_append_gt      = True,\n",
    "    mask_in_features        = None, #optional\n",
    "    mask_pooler             = None, #optional\n",
    "    mask_head               = None, #optional\n",
    "    keypoint_in_features    = None, #optional\n",
    "    keypoint_pooler         = None, #optional\n",
    "    keypoint_head           = None, #optional\n",
    "    train_on_pred_boxes     = cfg.MODEL.ROI_BOX_HEAD.TRAIN_ON_PRED_BOXES\n",
    ")\n",
    "# roi_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn_101 = RCNN(\n",
    "    backbone            = backbone,\n",
    "    proposal_generator  = proposal_generator,\n",
    "    roi_heads           = roi_heads,\n",
    "    pixel_mean          = cfg.MODEL.PIXEL_MEAN,\n",
    "    pixel_std           = cfg.MODEL.PIXEL_STD,\n",
    "    input_format        = None,\n",
    "    vis_period          = 0,\n",
    ")\n",
    "faster_rcnn_101 = faster_rcnn_101.to(device)\n",
    "# faster_rcnn_101 # model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "register_coco_instances(\"iSAID_train\", {}, \n",
    "                        \"/apps/local/shared/CV703/datasets/iSAID/iSAID_patches/train/instancesonly_filtered_train.json\",\n",
    "                        \"/apps/local/shared/CV703/datasets/iSAID/iSAID_patches/train/images/\")\n",
    "register_coco_instances(\"iSAID_val\", {}, \n",
    "                        \"/apps/local/shared/CV703/datasets/iSAID/iSAID_patches/val/instancesonly_filtered_val.json\",\n",
    "                        \"/apps/local/shared/CV703/datasets/iSAID/iSAID_patches/val/images/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_default_optimizer_params(\n",
    "    faster_rcnn_101, # model\n",
    "    base_lr             = cfg.SOLVER.BASE_LR,\n",
    "    weight_decay_norm   = cfg.SOLVER.WEIGHT_DECAY_NORM,\n",
    "    bias_lr_factor      = cfg.SOLVER.BIAS_LR_FACTOR,\n",
    "    weight_decay_bias   = cfg.SOLVER.WEIGHT_DECAY_BIAS,\n",
    ") \n",
    "# ^ this can be expanded further\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    params,\n",
    "    lr              = cfg.SOLVER.BASE_LR,\n",
    "    momentum        = cfg.SOLVER.MOMENTUM,\n",
    "    nesterov        = cfg.SOLVER.NESTEROV,\n",
    "    weight_decay    = cfg.SOLVER.WEIGHT_DECAY,\n",
    ")\n",
    "# optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/26 21:18:55 d2.data.datasets.coco]: \u001b[0mLoading /apps/local/shared/CV703/datasets/iSAID/iSAID_patches/train/instancesonly_filtered_train.json takes 20.78 seconds.\n",
      "\u001b[32m[11/26 21:18:56 d2.data.datasets.coco]: \u001b[0mLoaded 28029 images in COCO format from /apps/local/shared/CV703/datasets/iSAID/iSAID_patches/train/instancesonly_filtered_train.json\n",
      "\u001b[32m[11/26 21:19:02 d2.data.build]: \u001b[0mRemoved 9300 images with no usable annotations. 18729 images left.\n",
      "\u001b[32m[11/26 21:19:02 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|     ship      | 79124        | storage_tank  | 13007        | baseball_di.. | 1122         |\n",
      "| tennis_court  | 6445         | basketball_.. | 1487         | Ground_Trac.. | 1175         |\n",
      "|    Bridge     | 4455         | Large_Vehicle | 80708        | Small_Vehicle | 474600       |\n",
      "|  Helicopter   | 1437         | Swimming_pool | 4907         |  Roundabout   | 955          |\n",
      "| Soccer_ball.. | 1574         |     plane     | 18437        |    Harbor     | 14995        |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 704428       |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[11/26 21:19:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomCrop(crop_type='relative', crop_size=[0.8, 0.8]), RandomRotation(angle=(45, 45)), RandomFlip()]\n",
      "\u001b[32m[11/26 21:19:02 d2.data.common]: \u001b[0mSerializing 18729 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/26 21:19:05 d2.data.common]: \u001b[0mSerialized dataset takes 325.11 MiB\n"
     ]
    }
   ],
   "source": [
    "is_train = True\n",
    "dataset = get_detection_dataset_dicts(\n",
    "    cfg.DATASETS.TRAIN,\n",
    "    filter_empty    = cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS,\n",
    "    min_keypoints   = cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE\n",
    "                    if cfg.MODEL.KEYPOINT_ON\n",
    "                    else 0,\n",
    "    proposal_files  = cfg.DATASETS.PROPOSAL_FILES_TRAIN if cfg.MODEL.LOAD_PROPOSALS else None,\n",
    ")\n",
    "\n",
    "sampler = TrainingSampler(len(dataset))\n",
    "\n",
    "augmentations = [\n",
    "    T.ResizeShortestEdge(\n",
    "        cfg.INPUT.MIN_SIZE_TRAIN, \n",
    "        cfg.INPUT.MAX_SIZE_TRAIN, \n",
    "        cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING\n",
    "    ),\n",
    "    T.RandomCrop(\n",
    "        crop_size = [0.8, 0.8],\n",
    "        crop_type = \"relative\"\n",
    "    ),\n",
    "    T.RandomRotation(\n",
    "        angle = 45,\n",
    "        expand = True\n",
    "    ),\n",
    "    T.RandomFlip(\n",
    "        horizontal  = cfg.INPUT.RANDOM_FLIP == \"horizontal\",\n",
    "        vertical    = cfg.INPUT.RANDOM_FLIP == \"vertical\",\n",
    "    ),\n",
    "]\n",
    "if cfg.INPUT.CROP.ENABLED and is_train:\n",
    "    augmentations.insert(0, T.RandomCrop(cfg.INPUT.CROP.TYPE, cfg.INPUT.CROP.SIZE))\n",
    "    recompute_boxes = cfg.MODEL.MASK_ON\n",
    "else:\n",
    "    recompute_boxes = False\n",
    "\n",
    "mapper = DatasetMapper(\n",
    "    is_train                    = is_train,\n",
    "    augmentations               = augmentations,\n",
    "    image_format                = cfg.INPUT.FORMAT,\n",
    "    use_instance_mask           = cfg.MODEL.MASK_ON,\n",
    "    use_keypoint                = cfg.MODEL.KEYPOINT_ON,\n",
    "    instance_mask_format        = cfg.INPUT.MASK_FORMAT,\n",
    "    keypoint_hflip_indices      = None,\n",
    "    precomputed_proposal_topk   = None,\n",
    "    recompute_boxes             = recompute_boxes,\n",
    ")\n",
    "\n",
    "if isinstance(dataset, list):\n",
    "    dataset = DatasetFromList(dataset, copy=False)\n",
    "dataset = MapDataset(dataset, mapper)\n",
    "\n",
    "data_loader = build_batch_data_loader(\n",
    "    dataset,\n",
    "    sampler,\n",
    "    total_batch_size        = cfg.SOLVER.IMS_PER_BATCH,\n",
    "    aspect_ratio_grouping   = cfg.DATALOADER.ASPECT_RATIO_GROUPING,\n",
    "    num_workers             = cfg.DATALOADER.NUM_WORKERS,\n",
    "    collate_fn              = None,\n",
    ")\n",
    "# data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (60, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (60,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/26 21:19:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[11/26 21:23:30 d2.utils.events]: \u001b[0m eta: 7:17:29  iter: 999  total_loss: 1.273  loss_cls: 0.4853  loss_box_reg: 0.2906  loss_rpn_cls: 0.1986  loss_rpn_loc: 0.2584  time: 0.2622  data_time: 0.0017  lr: 0.0024975  max_mem: 10943M\n",
      "\u001b[32m[11/26 21:27:36 d2.utils.events]: \u001b[0m eta: 6:44:59  iter: 1999  total_loss: 1.334  loss_cls: 0.4569  loss_box_reg: 0.3926  loss_rpn_cls: 0.1928  loss_rpn_loc: 0.2354  time: 0.2541  data_time: 0.0016  lr: 0.0025  max_mem: 10943M\n",
      "\u001b[32m[11/26 21:31:33 d2.utils.events]: \u001b[0m eta: 6:29:42  iter: 2999  total_loss: 1.161  loss_cls: 0.3702  loss_box_reg: 0.4199  loss_rpn_cls: 0.17  loss_rpn_loc: 0.1257  time: 0.2484  data_time: 0.0013  lr: 0.0025  max_mem: 10943M\n",
      "\u001b[32m[11/26 21:35:34 d2.utils.events]: \u001b[0m eta: 6:28:36  iter: 3999  total_loss: 1.101  loss_cls: 0.3601  loss_box_reg: 0.3459  loss_rpn_cls: 0.1918  loss_rpn_loc: 0.1883  time: 0.2463  data_time: 0.0015  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:39:32 d2.utils.events]: \u001b[0m eta: 6:21:40  iter: 4999  total_loss: 1.193  loss_cls: 0.3933  loss_box_reg: 0.3497  loss_rpn_cls: 0.1574  loss_rpn_loc: 0.166  time: 0.2445  data_time: 0.0016  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:43:27 d2.utils.events]: \u001b[0m eta: 6:13:14  iter: 5999  total_loss: 0.9129  loss_cls: 0.3331  loss_box_reg: 0.314  loss_rpn_cls: 0.1591  loss_rpn_loc: 0.1708  time: 0.2429  data_time: 0.0014  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:47:25 d2.utils.events]: \u001b[0m eta: 6:14:05  iter: 6999  total_loss: 1.034  loss_cls: 0.3349  loss_box_reg: 0.3614  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.1227  time: 0.2421  data_time: 0.0014  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:51:23 d2.utils.events]: \u001b[0m eta: 6:09:22  iter: 7999  total_loss: 1.13  loss_cls: 0.3476  loss_box_reg: 0.4013  loss_rpn_cls: 0.1438  loss_rpn_loc: 0.1629  time: 0.2416  data_time: 0.0014  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:55:21 d2.utils.events]: \u001b[0m eta: 6:05:56  iter: 8999  total_loss: 0.7761  loss_cls: 0.2493  loss_box_reg: 0.3051  loss_rpn_cls: 0.1638  loss_rpn_loc: 0.1215  time: 0.2411  data_time: 0.0015  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 21:59:20 d2.utils.events]: \u001b[0m eta: 6:02:21  iter: 9999  total_loss: 1.082  loss_cls: 0.3546  loss_box_reg: 0.4189  loss_rpn_cls: 0.1359  loss_rpn_loc: 0.1897  time: 0.2409  data_time: 0.0015  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:03:19 d2.utils.events]: \u001b[0m eta: 5:58:36  iter: 10999  total_loss: 1.02  loss_cls: 0.3555  loss_box_reg: 0.3761  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.1584  time: 0.2407  data_time: 0.0015  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:07:16 d2.utils.events]: \u001b[0m eta: 5:53:18  iter: 11999  total_loss: 1.052  loss_cls: 0.3703  loss_box_reg: 0.3252  loss_rpn_cls: 0.1313  loss_rpn_loc: 0.1625  time: 0.2404  data_time: 0.0015  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:11:15 d2.utils.events]: \u001b[0m eta: 5:51:37  iter: 12999  total_loss: 0.7466  loss_cls: 0.2607  loss_box_reg: 0.276  loss_rpn_cls: 0.1358  loss_rpn_loc: 0.08073  time: 0.2402  data_time: 0.0022  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:15:14 d2.utils.events]: \u001b[0m eta: 5:48:04  iter: 13999  total_loss: 0.8869  loss_cls: 0.328  loss_box_reg: 0.3294  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.138  time: 0.2401  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:19:14 d2.utils.events]: \u001b[0m eta: 5:43:15  iter: 14999  total_loss: 0.938  loss_cls: 0.2899  loss_box_reg: 0.3204  loss_rpn_cls: 0.1561  loss_rpn_loc: 0.167  time: 0.2400  data_time: 0.0016  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:23:13 d2.utils.events]: \u001b[0m eta: 5:39:17  iter: 15999  total_loss: 1.201  loss_cls: 0.3669  loss_box_reg: 0.4143  loss_rpn_cls: 0.1469  loss_rpn_loc: 0.2171  time: 0.2400  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:27:13 d2.utils.events]: \u001b[0m eta: 5:35:50  iter: 16999  total_loss: 0.948  loss_cls: 0.256  loss_box_reg: 0.3642  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.1348  time: 0.2399  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:31:11 d2.utils.events]: \u001b[0m eta: 5:31:25  iter: 17999  total_loss: 0.9679  loss_cls: 0.3005  loss_box_reg: 0.3626  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.1327  time: 0.2399  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:35:09 d2.utils.events]: \u001b[0m eta: 5:26:59  iter: 18999  total_loss: 0.9613  loss_cls: 0.3225  loss_box_reg: 0.3484  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.1287  time: 0.2397  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:39:08 d2.utils.events]: \u001b[0m eta: 5:22:41  iter: 19999  total_loss: 0.9394  loss_cls: 0.246  loss_box_reg: 0.3035  loss_rpn_cls: 0.1296  loss_rpn_loc: 0.1422  time: 0.2396  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:43:07 d2.utils.events]: \u001b[0m eta: 5:19:11  iter: 20999  total_loss: 0.8744  loss_cls: 0.2315  loss_box_reg: 0.2988  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.1666  time: 0.2396  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:47:06 d2.utils.events]: \u001b[0m eta: 5:15:41  iter: 21999  total_loss: 0.9606  loss_cls: 0.3201  loss_box_reg: 0.3166  loss_rpn_cls: 0.1204  loss_rpn_loc: 0.1211  time: 0.2396  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:51:05 d2.utils.events]: \u001b[0m eta: 5:11:43  iter: 22999  total_loss: 0.7222  loss_cls: 0.227  loss_box_reg: 0.2373  loss_rpn_cls: 0.1104  loss_rpn_loc: 0.07363  time: 0.2395  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:55:02 d2.utils.events]: \u001b[0m eta: 5:06:14  iter: 23999  total_loss: 1.053  loss_cls: 0.293  loss_box_reg: 0.3864  loss_rpn_cls: 0.1533  loss_rpn_loc: 0.174  time: 0.2394  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 22:59:04 d2.utils.events]: \u001b[0m eta: 5:03:55  iter: 24999  total_loss: 0.9186  loss_cls: 0.3238  loss_box_reg: 0.3484  loss_rpn_cls: 0.1574  loss_rpn_loc: 0.1475  time: 0.2395  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:03:01 d2.utils.events]: \u001b[0m eta: 4:58:44  iter: 25999  total_loss: 1.097  loss_cls: 0.3235  loss_box_reg: 0.3375  loss_rpn_cls: 0.1616  loss_rpn_loc: 0.2222  time: 0.2394  data_time: 0.0016  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:07:01 d2.utils.events]: \u001b[0m eta: 4:54:58  iter: 26999  total_loss: 0.8999  loss_cls: 0.2776  loss_box_reg: 0.3034  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.1607  time: 0.2394  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:10:57 d2.utils.events]: \u001b[0m eta: 4:50:27  iter: 27999  total_loss: 0.9905  loss_cls: 0.3044  loss_box_reg: 0.3182  loss_rpn_cls: 0.1569  loss_rpn_loc: 0.1756  time: 0.2393  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:14:59 d2.utils.events]: \u001b[0m eta: 4:48:01  iter: 28999  total_loss: 1.068  loss_cls: 0.3285  loss_box_reg: 0.3435  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.2121  time: 0.2393  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:19:23 d2.utils.events]: \u001b[0m eta: 5:11:08  iter: 29999  total_loss: 0.8947  loss_cls: 0.2701  loss_box_reg: 0.319  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.1308  time: 0.2401  data_time: 0.0016  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:23:28 d2.utils.events]: \u001b[0m eta: 4:43:57  iter: 30999  total_loss: 0.7459  loss_cls: 0.2416  loss_box_reg: 0.269  loss_rpn_cls: 0.1398  loss_rpn_loc: 0.1185  time: 0.2403  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:27:40 d2.utils.events]: \u001b[0m eta: 4:50:03  iter: 31999  total_loss: 1.091  loss_cls: 0.2769  loss_box_reg: 0.3943  loss_rpn_cls: 0.139  loss_rpn_loc: 0.1818  time: 0.2406  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:31:39 d2.utils.events]: \u001b[0m eta: 4:30:46  iter: 32999  total_loss: 0.8946  loss_cls: 0.2899  loss_box_reg: 0.314  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.138  time: 0.2406  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:35:39 d2.utils.events]: \u001b[0m eta: 4:27:19  iter: 33999  total_loss: 0.804  loss_cls: 0.2537  loss_box_reg: 0.3197  loss_rpn_cls: 0.1265  loss_rpn_loc: 0.1195  time: 0.2405  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:39:39 d2.utils.events]: \u001b[0m eta: 4:23:00  iter: 34999  total_loss: 0.8499  loss_cls: 0.277  loss_box_reg: 0.3278  loss_rpn_cls: 0.122  loss_rpn_loc: 0.09955  time: 0.2405  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:43:39 d2.utils.events]: \u001b[0m eta: 4:19:30  iter: 35999  total_loss: 0.8735  loss_cls: 0.2921  loss_box_reg: 0.3071  loss_rpn_cls: 0.1429  loss_rpn_loc: 0.1362  time: 0.2405  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:47:38 d2.utils.events]: \u001b[0m eta: 4:14:32  iter: 36999  total_loss: 0.8609  loss_cls: 0.2441  loss_box_reg: 0.266  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.1545  time: 0.2404  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:51:37 d2.utils.events]: \u001b[0m eta: 4:11:09  iter: 37999  total_loss: 0.8355  loss_cls: 0.2553  loss_box_reg: 0.3609  loss_rpn_cls: 0.118  loss_rpn_loc: 0.146  time: 0.2404  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:55:35 d2.utils.events]: \u001b[0m eta: 4:06:11  iter: 38999  total_loss: 0.9672  loss_cls: 0.2916  loss_box_reg: 0.3293  loss_rpn_cls: 0.144  loss_rpn_loc: 0.1868  time: 0.2403  data_time: 0.0090  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/26 23:59:37 d2.utils.events]: \u001b[0m eta: 4:02:54  iter: 39999  total_loss: 0.749  loss_cls: 0.2457  loss_box_reg: 0.2772  loss_rpn_cls: 0.112  loss_rpn_loc: 0.1307  time: 0.2403  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:03:37 d2.utils.events]: \u001b[0m eta: 3:58:22  iter: 40999  total_loss: 0.9401  loss_cls: 0.2539  loss_box_reg: 0.3609  loss_rpn_cls: 0.125  loss_rpn_loc: 0.1415  time: 0.2403  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:07:34 d2.utils.events]: \u001b[0m eta: 3:53:58  iter: 41999  total_loss: 1.087  loss_cls: 0.313  loss_box_reg: 0.3007  loss_rpn_cls: 0.1816  loss_rpn_loc: 0.2421  time: 0.2402  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:11:36 d2.utils.events]: \u001b[0m eta: 3:52:00  iter: 42999  total_loss: 0.8319  loss_cls: 0.2329  loss_box_reg: 0.26  loss_rpn_cls: 0.1448  loss_rpn_loc: 0.1689  time: 0.2403  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:15:40 d2.utils.events]: \u001b[0m eta: 3:49:39  iter: 43999  total_loss: 0.8614  loss_cls: 0.2416  loss_box_reg: 0.3281  loss_rpn_cls: 0.08155  loss_rpn_loc: 0.09936  time: 0.2404  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:19:47 d2.utils.events]: \u001b[0m eta: 3:46:23  iter: 44999  total_loss: 0.8714  loss_cls: 0.2956  loss_box_reg: 0.3271  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.1518  time: 0.2405  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:23:45 d2.utils.events]: \u001b[0m eta: 3:38:38  iter: 45999  total_loss: 0.8564  loss_cls: 0.2405  loss_box_reg: 0.2957  loss_rpn_cls: 0.1321  loss_rpn_loc: 0.1751  time: 0.2404  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:27:43 d2.utils.events]: \u001b[0m eta: 3:34:23  iter: 46999  total_loss: 0.8578  loss_cls: 0.2478  loss_box_reg: 0.3219  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1356  time: 0.2404  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:31:43 d2.utils.events]: \u001b[0m eta: 3:30:47  iter: 47999  total_loss: 0.8498  loss_cls: 0.2643  loss_box_reg: 0.3001  loss_rpn_cls: 0.1329  loss_rpn_loc: 0.1328  time: 0.2403  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:35:42 d2.utils.events]: \u001b[0m eta: 3:26:29  iter: 48999  total_loss: 1.032  loss_cls: 0.318  loss_box_reg: 0.331  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.1774  time: 0.2403  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:39:57 d2.utils.events]: \u001b[0m eta: 3:34:05  iter: 49999  total_loss: 0.9175  loss_cls: 0.2435  loss_box_reg: 0.3333  loss_rpn_cls: 0.1375  loss_rpn_loc: 0.1897  time: 0.2406  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:44:02 d2.utils.events]: \u001b[0m eta: 3:21:40  iter: 50999  total_loss: 0.8309  loss_cls: 0.2372  loss_box_reg: 0.3386  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.1136  time: 0.2407  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:48:05 d2.utils.events]: \u001b[0m eta: 3:15:30  iter: 51999  total_loss: 0.9406  loss_cls: 0.2436  loss_box_reg: 0.3018  loss_rpn_cls: 0.09865  loss_rpn_loc: 0.1653  time: 0.2407  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:52:12 d2.utils.events]: \u001b[0m eta: 3:14:53  iter: 52999  total_loss: 0.6816  loss_cls: 0.2361  loss_box_reg: 0.2614  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.09715  time: 0.2408  data_time: 0.0017  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 00:56:18 d2.utils.events]: \u001b[0m eta: 3:09:25  iter: 53999  total_loss: 0.8861  loss_cls: 0.2384  loss_box_reg: 0.3518  loss_rpn_cls: 0.1191  loss_rpn_loc: 0.1512  time: 0.2409  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 01:00:35 d2.utils.events]: \u001b[0m eta: 3:15:30  iter: 54999  total_loss: 1.012  loss_cls: 0.2617  loss_box_reg: 0.3915  loss_rpn_cls: 0.1507  loss_rpn_loc: 0.1987  time: 0.2412  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 01:04:59 d2.utils.events]: \u001b[0m eta: 3:16:32  iter: 55999  total_loss: 0.7142  loss_cls: 0.2045  loss_box_reg: 0.2623  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.1403  time: 0.2416  data_time: 0.0018  lr: 0.0025  max_mem: 16773M\n",
      "\u001b[32m[11/27 01:09:14 d2.utils.events]: \u001b[0m eta: 3:04:28  iter: 56999  total_loss: 0.8401  loss_cls: 0.2414  loss_box_reg: 0.281  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1509  time: 0.2418  data_time: 0.0018  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:13:22 d2.utils.events]: \u001b[0m eta: 2:54:39  iter: 57999  total_loss: 0.8085  loss_cls: 0.217  loss_box_reg: 0.3372  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.08357  time: 0.2419  data_time: 0.0020  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:17:27 d2.utils.events]: \u001b[0m eta: 2:49:05  iter: 58999  total_loss: 0.8517  loss_cls: 0.2873  loss_box_reg: 0.329  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.08026  time: 0.2420  data_time: 0.0017  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:21:34 d2.utils.events]: \u001b[0m eta: 2:45:00  iter: 59999  total_loss: 0.8744  loss_cls: 0.2295  loss_box_reg: 0.3351  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.1883  time: 0.2420  data_time: 0.0017  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:25:40 d2.utils.events]: \u001b[0m eta: 2:40:23  iter: 60999  total_loss: 0.7752  loss_cls: 0.2036  loss_box_reg: 0.3018  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.149  time: 0.2421  data_time: 0.0017  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:29:43 d2.utils.events]: \u001b[0m eta: 2:35:04  iter: 61999  total_loss: 0.948  loss_cls: 0.2737  loss_box_reg: 0.3224  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.1437  time: 0.2421  data_time: 0.0017  lr: 0.0025  max_mem: 16778M\n",
      "\u001b[32m[11/27 01:33:49 d2.utils.events]: \u001b[0m eta: 2:32:40  iter: 62999  total_loss: 0.8746  loss_cls: 0.2566  loss_box_reg: 0.3497  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.1423  time: 0.2422  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:38:04 d2.utils.events]: \u001b[0m eta: 2:35:18  iter: 63999  total_loss: 0.8819  loss_cls: 0.2645  loss_box_reg: 0.3087  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.1709  time: 0.2424  data_time: 0.0018  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:42:22 d2.utils.events]: \u001b[0m eta: 2:31:40  iter: 64999  total_loss: 0.727  loss_cls: 0.2016  loss_box_reg: 0.281  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.08906  time: 0.2426  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:46:20 d2.utils.events]: \u001b[0m eta: 2:16:56  iter: 65999  total_loss: 0.8036  loss_cls: 0.2423  loss_box_reg: 0.3052  loss_rpn_cls: 0.1222  loss_rpn_loc: 0.1704  time: 0.2425  data_time: 0.0016  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:50:18 d2.utils.events]: \u001b[0m eta: 2:13:17  iter: 66999  total_loss: 0.8005  loss_cls: 0.236  loss_box_reg: 0.3132  loss_rpn_cls: 0.1097  loss_rpn_loc: 0.1534  time: 0.2425  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:54:32 d2.utils.events]: \u001b[0m eta: 2:17:30  iter: 67999  total_loss: 0.8518  loss_cls: 0.2393  loss_box_reg: 0.2916  loss_rpn_cls: 0.1305  loss_rpn_loc: 0.1306  time: 0.2426  data_time: 0.0018  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 01:58:50 d2.utils.events]: \u001b[0m eta: 2:15:38  iter: 68999  total_loss: 0.8613  loss_cls: 0.3235  loss_box_reg: 0.3135  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.1207  time: 0.2428  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:02:50 d2.utils.events]: \u001b[0m eta: 2:01:08  iter: 69999  total_loss: 0.9014  loss_cls: 0.2406  loss_box_reg: 0.3152  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.1591  time: 0.2428  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:06:47 d2.utils.events]: \u001b[0m eta: 1:56:47  iter: 70999  total_loss: 0.8348  loss_cls: 0.2401  loss_box_reg: 0.2873  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1181  time: 0.2427  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:10:46 d2.utils.events]: \u001b[0m eta: 1:52:37  iter: 71999  total_loss: 0.9305  loss_cls: 0.2589  loss_box_reg: 0.3499  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.1752  time: 0.2426  data_time: 0.0019  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:14:45 d2.utils.events]: \u001b[0m eta: 1:48:55  iter: 72999  total_loss: 0.8355  loss_cls: 0.2409  loss_box_reg: 0.3016  loss_rpn_cls: 0.1204  loss_rpn_loc: 0.1453  time: 0.2426  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:18:43 d2.utils.events]: \u001b[0m eta: 1:44:39  iter: 73999  total_loss: 0.7877  loss_cls: 0.2354  loss_box_reg: 0.323  loss_rpn_cls: 0.08984  loss_rpn_loc: 0.08641  time: 0.2425  data_time: 0.0018  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:22:41 d2.utils.events]: \u001b[0m eta: 1:40:52  iter: 74999  total_loss: 0.9417  loss_cls: 0.284  loss_box_reg: 0.3711  loss_rpn_cls: 0.1299  loss_rpn_loc: 0.1555  time: 0.2425  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:26:39 d2.utils.events]: \u001b[0m eta: 1:36:38  iter: 75999  total_loss: 0.7944  loss_cls: 0.2759  loss_box_reg: 0.2846  loss_rpn_cls: 0.1268  loss_rpn_loc: 0.1248  time: 0.2424  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:30:36 d2.utils.events]: \u001b[0m eta: 1:32:20  iter: 76999  total_loss: 0.779  loss_cls: 0.2306  loss_box_reg: 0.2759  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.1383  time: 0.2423  data_time: 0.0017  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:34:33 d2.utils.events]: \u001b[0m eta: 1:28:31  iter: 77999  total_loss: 0.8373  loss_cls: 0.2799  loss_box_reg: 0.3607  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.09544  time: 0.2422  data_time: 0.0016  lr: 0.0025  max_mem: 16787M\n",
      "\u001b[32m[11/27 02:38:32 d2.utils.events]: \u001b[0m eta: 1:24:43  iter: 78999  total_loss: 0.9041  loss_cls: 0.276  loss_box_reg: 0.3458  loss_rpn_cls: 0.115  loss_rpn_loc: 0.17  time: 0.2422  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 02:42:29 d2.utils.events]: \u001b[0m eta: 1:20:25  iter: 79999  total_loss: 0.8188  loss_cls: 0.2642  loss_box_reg: 0.3389  loss_rpn_cls: 0.1124  loss_rpn_loc: 0.1349  time: 0.2421  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 02:46:26 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 80999  total_loss: 0.788  loss_cls: 0.2074  loss_box_reg: 0.3063  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.09941  time: 0.2421  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 02:50:25 d2.utils.events]: \u001b[0m eta: 1:12:34  iter: 81999  total_loss: 0.9324  loss_cls: 0.2691  loss_box_reg: 0.3331  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.1012  time: 0.2420  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 02:54:26 d2.utils.events]: \u001b[0m eta: 1:08:55  iter: 82999  total_loss: 0.8414  loss_cls: 0.2395  loss_box_reg: 0.2728  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.1116  time: 0.2420  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 02:58:25 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 83999  total_loss: 0.7728  loss_cls: 0.2455  loss_box_reg: 0.2628  loss_rpn_cls: 0.1307  loss_rpn_loc: 0.1434  time: 0.2420  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:02:24 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 84999  total_loss: 0.6998  loss_cls: 0.1803  loss_box_reg: 0.274  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.1253  time: 0.2419  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:06:22 d2.utils.events]: \u001b[0m eta: 0:56:29  iter: 85999  total_loss: 0.845  loss_cls: 0.2759  loss_box_reg: 0.3184  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.1219  time: 0.2419  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:10:20 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 86999  total_loss: 0.7607  loss_cls: 0.2711  loss_box_reg: 0.2773  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.1401  time: 0.2418  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:14:19 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 87999  total_loss: 0.7702  loss_cls: 0.2885  loss_box_reg: 0.298  loss_rpn_cls: 0.1222  loss_rpn_loc: 0.1029  time: 0.2418  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:18:17 d2.utils.events]: \u001b[0m eta: 0:44:21  iter: 88999  total_loss: 0.6962  loss_cls: 0.1948  loss_box_reg: 0.28  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1215  time: 0.2417  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:22:17 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 89999  total_loss: 0.8585  loss_cls: 0.2673  loss_box_reg: 0.3352  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.1572  time: 0.2417  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:26:15 d2.utils.events]: \u001b[0m eta: 0:36:14  iter: 90999  total_loss: 0.801  loss_cls: 0.2188  loss_box_reg: 0.3129  loss_rpn_cls: 0.09758  loss_rpn_loc: 0.09044  time: 0.2417  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:30:11 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 91999  total_loss: 1.067  loss_cls: 0.3323  loss_box_reg: 0.382  loss_rpn_cls: 0.1306  loss_rpn_loc: 0.1814  time: 0.2416  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:34:08 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 92999  total_loss: 0.8587  loss_cls: 0.1925  loss_box_reg: 0.3112  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.08173  time: 0.2415  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:38:05 d2.utils.events]: \u001b[0m eta: 0:24:08  iter: 93999  total_loss: 0.9389  loss_cls: 0.2509  loss_box_reg: 0.3327  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.1754  time: 0.2415  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:42:05 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 94999  total_loss: 0.8412  loss_cls: 0.2369  loss_box_reg: 0.3205  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.1631  time: 0.2415  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:46:04 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 95999  total_loss: 1.003  loss_cls: 0.2868  loss_box_reg: 0.3302  loss_rpn_cls: 0.1345  loss_rpn_loc: 0.1908  time: 0.2414  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:50:02 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 96999  total_loss: 0.9742  loss_cls: 0.2343  loss_box_reg: 0.2899  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.1432  time: 0.2414  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:53:59 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 97999  total_loss: 0.8443  loss_cls: 0.2706  loss_box_reg: 0.2794  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.1193  time: 0.2414  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 03:57:57 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 98999  total_loss: 0.7121  loss_cls: 0.2102  loss_box_reg: 0.2964  loss_rpn_cls: 0.09952  loss_rpn_loc: 0.09555  time: 0.2413  data_time: 0.0017  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 04:01:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 99999  total_loss: 0.6299  loss_cls: 0.1853  loss_box_reg: 0.2908  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.06318  time: 0.2413  data_time: 0.0016  lr: 0.0025  max_mem: 16788M\n",
      "\u001b[32m[11/27 04:01:58 d2.engine.hooks]: \u001b[0mOverall training speed: 99998 iterations in 6:42:09 (0.2413 s / it)\n",
      "\u001b[32m[11/27 04:01:58 d2.engine.hooks]: \u001b[0mTotal training time: 6:42:49 (0:00:39 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg, model=faster_rcnn_101, optimizer=optimizer, data_loader=data_loader) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg, model=faster_rcnn_101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/27 16:19:29 d2.data.datasets.coco]: \u001b[0mLoading /apps/local/shared/CV703/datasets/iSAID/iSAID_patches/val/instancesonly_filtered_val.json takes 5.97 seconds.\n",
      "\u001b[32m[11/27 16:19:29 d2.data.datasets.coco]: \u001b[0mLoaded 9512 images in COCO format from /apps/local/shared/CV703/datasets/iSAID/iSAID_patches/val/instancesonly_filtered_val.json\n",
      "\u001b[32m[11/27 16:19:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/27 16:19:30 d2.data.common]: \u001b[0mSerializing 9512 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/27 16:19:31 d2.data.common]: \u001b[0mSerialized dataset takes 111.29 MiB\n",
      "\u001b[32m[11/27 16:19:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 9512 batches\n",
      "\u001b[32m[11/27 16:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/9512. Dataloading: 0.0006 s/iter. Inference: 0.0513 s/iter. Eval: 0.0003 s/iter. Total: 0.0522 s/iter. ETA=0:08:16\n",
      "\u001b[32m[11/27 16:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 106/9512. Dataloading: 0.0007 s/iter. Inference: 0.0582 s/iter. Eval: 0.0003 s/iter. Total: 0.0593 s/iter. ETA=0:09:17\n",
      "\u001b[32m[11/27 16:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 201/9512. Dataloading: 0.0007 s/iter. Inference: 0.0552 s/iter. Eval: 0.0003 s/iter. Total: 0.0562 s/iter. ETA=0:08:43\n",
      "\u001b[32m[11/27 16:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 283/9512. Dataloading: 0.0032 s/iter. Inference: 0.0542 s/iter. Eval: 0.0003 s/iter. Total: 0.0577 s/iter. ETA=0:08:52\n",
      "\u001b[32m[11/27 16:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 378/9512. Dataloading: 0.0026 s/iter. Inference: 0.0536 s/iter. Eval: 0.0003 s/iter. Total: 0.0566 s/iter. ETA=0:08:36\n",
      "\u001b[32m[11/27 16:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 473/9512. Dataloading: 0.0022 s/iter. Inference: 0.0533 s/iter. Eval: 0.0003 s/iter. Total: 0.0558 s/iter. ETA=0:08:24\n",
      "\u001b[32m[11/27 16:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 566/9512. Dataloading: 0.0020 s/iter. Inference: 0.0532 s/iter. Eval: 0.0003 s/iter. Total: 0.0555 s/iter. ETA=0:08:16\n",
      "\u001b[32m[11/27 16:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 660/9512. Dataloading: 0.0018 s/iter. Inference: 0.0531 s/iter. Eval: 0.0003 s/iter. Total: 0.0552 s/iter. ETA=0:08:08\n",
      "\u001b[32m[11/27 16:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 753/9512. Dataloading: 0.0016 s/iter. Inference: 0.0531 s/iter. Eval: 0.0003 s/iter. Total: 0.0551 s/iter. ETA=0:08:02\n",
      "\u001b[32m[11/27 16:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 847/9512. Dataloading: 0.0015 s/iter. Inference: 0.0530 s/iter. Eval: 0.0003 s/iter. Total: 0.0549 s/iter. ETA=0:07:55\n",
      "\u001b[32m[11/27 16:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 928/9512. Dataloading: 0.0022 s/iter. Inference: 0.0530 s/iter. Eval: 0.0003 s/iter. Total: 0.0555 s/iter. ETA=0:07:56\n",
      "\u001b[32m[11/27 16:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 1021/9512. Dataloading: 0.0021 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0553 s/iter. ETA=0:07:49\n",
      "\u001b[32m[11/27 16:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 1114/9512. Dataloading: 0.0019 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0552 s/iter. ETA=0:07:43\n",
      "\u001b[32m[11/27 16:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 1207/9512. Dataloading: 0.0018 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0551 s/iter. ETA=0:07:37\n",
      "\u001b[32m[11/27 16:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 1300/9512. Dataloading: 0.0018 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0551 s/iter. ETA=0:07:32\n",
      "\u001b[32m[11/27 16:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 1393/9512. Dataloading: 0.0017 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0550 s/iter. ETA=0:07:26\n",
      "\u001b[32m[11/27 16:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 1486/9512. Dataloading: 0.0016 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0549 s/iter. ETA=0:07:20\n",
      "\u001b[32m[11/27 16:20:58 d2.evaluation.evaluator]: \u001b[0mInference done 1579/9512. Dataloading: 0.0016 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0549 s/iter. ETA=0:07:15\n",
      "\u001b[32m[11/27 16:21:03 d2.evaluation.evaluator]: \u001b[0mInference done 1672/9512. Dataloading: 0.0015 s/iter. Inference: 0.0529 s/iter. Eval: 0.0003 s/iter. Total: 0.0548 s/iter. ETA=0:07:09\n",
      "\u001b[32m[11/27 16:21:08 d2.evaluation.evaluator]: \u001b[0mInference done 1751/9512. Dataloading: 0.0015 s/iter. Inference: 0.0530 s/iter. Eval: 0.0007 s/iter. Total: 0.0552 s/iter. ETA=0:07:08\n",
      "\u001b[32m[11/27 16:21:13 d2.evaluation.evaluator]: \u001b[0mInference done 1844/9512. Dataloading: 0.0014 s/iter. Inference: 0.0530 s/iter. Eval: 0.0007 s/iter. Total: 0.0552 s/iter. ETA=0:07:02\n",
      "\u001b[32m[11/27 16:21:18 d2.evaluation.evaluator]: \u001b[0mInference done 1937/9512. Dataloading: 0.0014 s/iter. Inference: 0.0530 s/iter. Eval: 0.0007 s/iter. Total: 0.0551 s/iter. ETA=0:06:57\n",
      "\u001b[32m[11/27 16:21:23 d2.evaluation.evaluator]: \u001b[0mInference done 2030/9512. Dataloading: 0.0014 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:06:51\n",
      "\u001b[32m[11/27 16:21:28 d2.evaluation.evaluator]: \u001b[0mInference done 2124/9512. Dataloading: 0.0013 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:06:46\n",
      "\u001b[32m[11/27 16:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 2218/9512. Dataloading: 0.0013 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:06:40\n",
      "\u001b[32m[11/27 16:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 2311/9512. Dataloading: 0.0013 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:06:35\n",
      "\u001b[32m[11/27 16:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 2404/9512. Dataloading: 0.0013 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:06:29\n",
      "\u001b[32m[11/27 16:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 2497/9512. Dataloading: 0.0013 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:06:24\n",
      "\u001b[32m[11/27 16:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 2590/9512. Dataloading: 0.0012 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:06:19\n",
      "\u001b[32m[11/27 16:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 2683/9512. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:06:14\n",
      "\u001b[32m[11/27 16:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 2775/9512. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:06:09\n",
      "\u001b[32m[11/27 16:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 2868/9512. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:06:03\n",
      "\u001b[32m[11/27 16:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 2959/9512. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:58\n",
      "\u001b[32m[11/27 16:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 3051/9512. Dataloading: 0.0012 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:53\n",
      "\u001b[32m[11/27 16:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 3143/9512. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:48\n",
      "\u001b[32m[11/27 16:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 3235/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:43\n",
      "\u001b[32m[11/27 16:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 3326/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:38\n",
      "\u001b[32m[11/27 16:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 3418/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:33\n",
      "\u001b[32m[11/27 16:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 3510/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:28\n",
      "\u001b[32m[11/27 16:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 3602/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0005 s/iter. Total: 0.0548 s/iter. ETA=0:05:23\n",
      "\u001b[32m[11/27 16:22:54 d2.evaluation.evaluator]: \u001b[0mInference done 3677/9512. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:05:21\n",
      "\u001b[32m[11/27 16:22:59 d2.evaluation.evaluator]: \u001b[0mInference done 3768/9512. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:05:16\n",
      "\u001b[32m[11/27 16:23:04 d2.evaluation.evaluator]: \u001b[0mInference done 3860/9512. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:05:10\n",
      "\u001b[32m[11/27 16:23:09 d2.evaluation.evaluator]: \u001b[0mInference done 3952/9512. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:05:05\n",
      "\u001b[32m[11/27 16:23:14 d2.evaluation.evaluator]: \u001b[0mInference done 4044/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:05:00\n",
      "\u001b[32m[11/27 16:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 4136/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:04:55\n",
      "\u001b[32m[11/27 16:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 4228/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:04:50\n",
      "\u001b[32m[11/27 16:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 4320/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0007 s/iter. Total: 0.0550 s/iter. ETA=0:04:45\n",
      "\u001b[32m[11/27 16:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 4412/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:04:40\n",
      "\u001b[32m[11/27 16:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 4504/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:04:35\n",
      "\u001b[32m[11/27 16:23:44 d2.evaluation.evaluator]: \u001b[0mInference done 4596/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:04:30\n",
      "\u001b[32m[11/27 16:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 4688/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:04:25\n",
      "\u001b[32m[11/27 16:23:54 d2.evaluation.evaluator]: \u001b[0mInference done 4780/9512. Dataloading: 0.0010 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:04:19\n",
      "\u001b[32m[11/27 16:23:59 d2.evaluation.evaluator]: \u001b[0mInference done 4874/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:04:14\n",
      "\u001b[32m[11/27 16:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 4967/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:04:09\n",
      "\u001b[32m[11/27 16:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 5060/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:04:04\n",
      "\u001b[32m[11/27 16:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 5153/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:03:59\n",
      "\u001b[32m[11/27 16:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 5247/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:03:53\n",
      "\u001b[32m[11/27 16:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 5341/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:03:48\n",
      "\u001b[32m[11/27 16:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 5435/9512. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:03:43\n",
      "\u001b[32m[11/27 16:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 5536/9512. Dataloading: 0.0010 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:03:37\n",
      "\u001b[32m[11/27 16:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 5637/9512. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0546 s/iter. ETA=0:03:31\n",
      "\u001b[32m[11/27 16:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 5738/9512. Dataloading: 0.0009 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0545 s/iter. ETA=0:03:25\n",
      "\u001b[32m[11/27 16:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 5839/9512. Dataloading: 0.0009 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0545 s/iter. ETA=0:03:20\n",
      "\u001b[32m[11/27 16:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 5940/9512. Dataloading: 0.0009 s/iter. Inference: 0.0528 s/iter. Eval: 0.0005 s/iter. Total: 0.0544 s/iter. ETA=0:03:14\n",
      "\u001b[32m[11/27 16:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 6041/9512. Dataloading: 0.0009 s/iter. Inference: 0.0528 s/iter. Eval: 0.0005 s/iter. Total: 0.0543 s/iter. ETA=0:03:08\n",
      "\u001b[32m[11/27 16:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 6142/9512. Dataloading: 0.0009 s/iter. Inference: 0.0527 s/iter. Eval: 0.0005 s/iter. Total: 0.0542 s/iter. ETA=0:03:02\n",
      "\u001b[32m[11/27 16:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 6226/9512. Dataloading: 0.0009 s/iter. Inference: 0.0528 s/iter. Eval: 0.0005 s/iter. Total: 0.0543 s/iter. ETA=0:02:58\n",
      "\u001b[32m[11/27 16:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 6327/9512. Dataloading: 0.0009 s/iter. Inference: 0.0527 s/iter. Eval: 0.0005 s/iter. Total: 0.0542 s/iter. ETA=0:02:52\n",
      "\u001b[32m[11/27 16:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 6428/9512. Dataloading: 0.0009 s/iter. Inference: 0.0526 s/iter. Eval: 0.0005 s/iter. Total: 0.0542 s/iter. ETA=0:02:47\n",
      "\u001b[32m[11/27 16:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 6529/9512. Dataloading: 0.0009 s/iter. Inference: 0.0526 s/iter. Eval: 0.0005 s/iter. Total: 0.0541 s/iter. ETA=0:02:41\n",
      "\u001b[32m[11/27 16:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 6630/9512. Dataloading: 0.0009 s/iter. Inference: 0.0525 s/iter. Eval: 0.0005 s/iter. Total: 0.0540 s/iter. ETA=0:02:35\n",
      "\u001b[32m[11/27 16:25:35 d2.evaluation.evaluator]: \u001b[0mInference done 6731/9512. Dataloading: 0.0009 s/iter. Inference: 0.0525 s/iter. Eval: 0.0005 s/iter. Total: 0.0540 s/iter. ETA=0:02:30\n",
      "\u001b[32m[11/27 16:25:40 d2.evaluation.evaluator]: \u001b[0mInference done 6832/9512. Dataloading: 0.0009 s/iter. Inference: 0.0524 s/iter. Eval: 0.0005 s/iter. Total: 0.0539 s/iter. ETA=0:02:24\n",
      "\u001b[32m[11/27 16:25:45 d2.evaluation.evaluator]: \u001b[0mInference done 6933/9512. Dataloading: 0.0009 s/iter. Inference: 0.0524 s/iter. Eval: 0.0005 s/iter. Total: 0.0538 s/iter. ETA=0:02:18\n",
      "\u001b[32m[11/27 16:25:50 d2.evaluation.evaluator]: \u001b[0mInference done 7033/9512. Dataloading: 0.0009 s/iter. Inference: 0.0523 s/iter. Eval: 0.0005 s/iter. Total: 0.0538 s/iter. ETA=0:02:13\n",
      "\u001b[32m[11/27 16:25:55 d2.evaluation.evaluator]: \u001b[0mInference done 7133/9512. Dataloading: 0.0009 s/iter. Inference: 0.0523 s/iter. Eval: 0.0005 s/iter. Total: 0.0537 s/iter. ETA=0:02:07\n",
      "\u001b[32m[11/27 16:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 7234/9512. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0005 s/iter. Total: 0.0537 s/iter. ETA=0:02:02\n",
      "\u001b[32m[11/27 16:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 7333/9512. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:01:56\n",
      "\u001b[32m[11/27 16:26:10 d2.evaluation.evaluator]: \u001b[0mInference done 7432/9512. Dataloading: 0.0009 s/iter. Inference: 0.0522 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:01:51\n",
      "\u001b[32m[11/27 16:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 7532/9512. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:01:46\n",
      "\u001b[32m[11/27 16:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 7632/9512. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0535 s/iter. ETA=0:01:40\n",
      "\u001b[32m[11/27 16:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 7733/9512. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0535 s/iter. ETA=0:01:35\n",
      "\u001b[32m[11/27 16:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 7835/9512. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0534 s/iter. ETA=0:01:29\n",
      "\u001b[32m[11/27 16:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 7936/9512. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0005 s/iter. Total: 0.0534 s/iter. ETA=0:01:24\n",
      "\u001b[32m[11/27 16:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 8037/9512. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0005 s/iter. Total: 0.0533 s/iter. ETA=0:01:18\n",
      "\u001b[32m[11/27 16:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 8138/9512. Dataloading: 0.0009 s/iter. Inference: 0.0519 s/iter. Eval: 0.0005 s/iter. Total: 0.0533 s/iter. ETA=0:01:13\n",
      "\u001b[32m[11/27 16:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 8240/9512. Dataloading: 0.0009 s/iter. Inference: 0.0518 s/iter. Eval: 0.0005 s/iter. Total: 0.0532 s/iter. ETA=0:01:07\n",
      "\u001b[32m[11/27 16:26:55 d2.evaluation.evaluator]: \u001b[0mInference done 8341/9512. Dataloading: 0.0009 s/iter. Inference: 0.0518 s/iter. Eval: 0.0005 s/iter. Total: 0.0532 s/iter. ETA=0:01:02\n",
      "\u001b[32m[11/27 16:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 8442/9512. Dataloading: 0.0009 s/iter. Inference: 0.0517 s/iter. Eval: 0.0005 s/iter. Total: 0.0531 s/iter. ETA=0:00:56\n",
      "\u001b[32m[11/27 16:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 8543/9512. Dataloading: 0.0009 s/iter. Inference: 0.0517 s/iter. Eval: 0.0005 s/iter. Total: 0.0531 s/iter. ETA=0:00:51\n",
      "\u001b[32m[11/27 16:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 8644/9512. Dataloading: 0.0009 s/iter. Inference: 0.0517 s/iter. Eval: 0.0005 s/iter. Total: 0.0531 s/iter. ETA=0:00:46\n",
      "\u001b[32m[11/27 16:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 8745/9512. Dataloading: 0.0009 s/iter. Inference: 0.0516 s/iter. Eval: 0.0005 s/iter. Total: 0.0530 s/iter. ETA=0:00:40\n",
      "\u001b[32m[11/27 16:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 8846/9512. Dataloading: 0.0009 s/iter. Inference: 0.0516 s/iter. Eval: 0.0005 s/iter. Total: 0.0530 s/iter. ETA=0:00:35\n",
      "\u001b[32m[11/27 16:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 8947/9512. Dataloading: 0.0009 s/iter. Inference: 0.0516 s/iter. Eval: 0.0005 s/iter. Total: 0.0530 s/iter. ETA=0:00:29\n",
      "\u001b[32m[11/27 16:27:30 d2.evaluation.evaluator]: \u001b[0mInference done 9048/9512. Dataloading: 0.0009 s/iter. Inference: 0.0515 s/iter. Eval: 0.0005 s/iter. Total: 0.0529 s/iter. ETA=0:00:24\n",
      "\u001b[32m[11/27 16:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 9149/9512. Dataloading: 0.0009 s/iter. Inference: 0.0515 s/iter. Eval: 0.0004 s/iter. Total: 0.0529 s/iter. ETA=0:00:19\n",
      "\u001b[32m[11/27 16:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 9241/9512. Dataloading: 0.0009 s/iter. Inference: 0.0515 s/iter. Eval: 0.0006 s/iter. Total: 0.0530 s/iter. ETA=0:00:14\n",
      "\u001b[32m[11/27 16:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 9342/9512. Dataloading: 0.0009 s/iter. Inference: 0.0515 s/iter. Eval: 0.0006 s/iter. Total: 0.0529 s/iter. ETA=0:00:09\n",
      "\u001b[32m[11/27 16:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 9443/9512. Dataloading: 0.0008 s/iter. Inference: 0.0514 s/iter. Eval: 0.0006 s/iter. Total: 0.0529 s/iter. ETA=0:00:03\n",
      "\u001b[32m[11/27 16:27:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:08:22.984962 (0.052907 s / iter per device, on 1 devices)\n",
      "\u001b[32m[11/27 16:27:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:08:08 (0.051419 s / iter per device, on 1 devices)\n",
      "\u001b[32m[11/27 16:27:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[11/27 16:27:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=3.53s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[11/27 16:27:59 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[11/27 16:28:09 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 10.12 seconds.\n",
      "\u001b[32m[11/27 16:28:09 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[11/27 16:28:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 2.32 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.165\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.040\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.059\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.196\n",
      "\u001b[32m[11/27 16:28:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 3.878 | 16.517 | 0.750  | 4.001 | 5.900 | 5.707 |\n",
      "\u001b[32m[11/27 16:28:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category          | AP    | category         | AP    | category           | AP    |\n",
      "|:------------------|:------|:-----------------|:------|:-------------------|:------|\n",
      "| ship              | 3.423 | storage_tank     | 1.314 | baseball_diamond   | 7.089 |\n",
      "| tennis_court      | 4.237 | basketball_court | 4.832 | Ground_Track_Field | 4.201 |\n",
      "| Bridge            | 1.225 | Large_Vehicle    | 2.686 | Small_Vehicle      | 1.564 |\n",
      "| Helicopter        | 0.578 | Swimming_pool    | 3.000 | Roundabout         | 7.045 |\n",
      "| Soccer_ball_field | 4.415 | plane            | 9.635 | Harbor             | 2.935 |\n",
      "OrderedDict([('bbox', {'AP': 3.8784879100646354, 'AP50': 16.51691038836172, 'AP75': 0.7503868230440726, 'APs': 4.000839194081456, 'APm': 5.900035790111321, 'APl': 5.706832318550255, 'AP-ship': 3.4229566288973285, 'AP-storage_tank': 1.3137961159512779, 'AP-baseball_diamond': 7.088871083077389, 'AP-tennis_court': 4.23693703567309, 'AP-basketball_court': 4.831772312644055, 'AP-Ground_Track_Field': 4.200562950609774, 'AP-Bridge': 1.2250693617579076, 'AP-Large_Vehicle': 2.6864276119210406, 'AP-Small_Vehicle': 1.564226939839895, 'AP-Helicopter': 0.5778616509554504, 'AP-Swimming_pool': 2.999741461990952, 'AP-Roundabout': 7.044622707344378, 'AP-Soccer_ball_field': 4.414940249292751, 'AP-plane': 9.634978154165685, 'AP-Harbor': 2.9345543868485673})])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluator = COCOEvaluator(\"iSAID_val\")\n",
    "val_loader = build_detection_test_loader(cfg, \"iSAID_val\")\n",
    "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edb3227acf2339b762c30c3271c81a9167bc3199bc5ecaad673774095a6c3b4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}